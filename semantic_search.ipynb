{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa1a533",
   "metadata": {},
   "source": [
    "# Semantic Search on ArXiv Data (Titles & Abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed4b832",
   "metadata": {},
   "source": [
    "### Dataset: ArXiv Abstracts from Papers With Code\n",
    "### Database: Milvus-lite\n",
    "### Embedding Model: Cohere's co.embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d6897f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install pymilvus gdown milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df4e8370",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install cohere\n",
    "#!pip install langchain[all]\n",
    "#! python -m pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "003a0d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import cohere\n",
    "from pymilvus import FieldSchema, CollectionSchema, DataType, Collection\n",
    "#from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "#from langchain.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8612e386",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the zip file that has ArXiv abstracts and titles collection\n",
    "# Ref for dataset: https://paperswithcode.com/dataset/arxiv-10\n",
    "# with zipfile.ZipFile(\"./ArXiv-10.zip\",\"r\") as zip_ref:\n",
    "#     zip_ref.extractall(\"./ArXiv-10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a431f490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The Pre-He White Dwarfs in Eclipsing Binaries....</td>\n",
       "      <td>We report the first $BV$ light curves and hi...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>A Possible Origin of kHZ QPOs in Low-Mass X-ra...</td>\n",
       "      <td>A possible origin of kHz QPOs in low-mass X-...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The effects of driving time scales on heating ...</td>\n",
       "      <td>Context. The relative importance of AC and D...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A new hard X-ray selected sample of extreme hi...</td>\n",
       "      <td>Extreme high-energy peaked BL Lac objects (E...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The baryon cycle of Seven Dwarfs with superbub...</td>\n",
       "      <td>We present results from a high-resolution, c...</td>\n",
       "      <td>astro-ph</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                              title  \\\n",
       "0      0  The Pre-He White Dwarfs in Eclipsing Binaries....   \n",
       "1      1  A Possible Origin of kHZ QPOs in Low-Mass X-ra...   \n",
       "2      2  The effects of driving time scales on heating ...   \n",
       "3      3  A new hard X-ray selected sample of extreme hi...   \n",
       "4      4  The baryon cycle of Seven Dwarfs with superbub...   \n",
       "\n",
       "                                            abstract     label  \n",
       "0    We report the first $BV$ light curves and hi...  astro-ph  \n",
       "1    A possible origin of kHz QPOs in low-mass X-...  astro-ph  \n",
       "2    Context. The relative importance of AC and D...  astro-ph  \n",
       "3    Extreme high-energy peaked BL Lac objects (E...  astro-ph  \n",
       "4    We present results from a high-resolution, c...  astro-ph  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the dataset into pandas dataframe and explore \n",
    "arxiv = pd.read_csv(\"./ArXiv-10/arxiv100.csv\")\n",
    "arxiv = arxiv.reset_index()\n",
    "arxiv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "188d4ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv = arxiv.rename(columns={'index': 'id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a191887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>49999.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>28867.657797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24999.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>49999.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>74999.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99999.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id\n",
       "count  100000.000000\n",
       "mean    49999.500000\n",
       "std     28867.657797\n",
       "min         0.000000\n",
       "25%     24999.750000\n",
       "50%     49999.500000\n",
       "75%     74999.250000\n",
       "max     99999.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff13e262",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NA\n",
    "arxiv = arxiv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "242abc60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['astro-ph', 'cond-mat', 'cs', 'eess', 'hep-ph', 'hep-th', 'math',\n",
       "       'physics', 'quant-ph', 'stat'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv['label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4849567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dataset into milvus db\n",
    "COLLECTION_NAME = \"arxiv_10000\"\n",
    "DIMENSION = 1024\n",
    "BATCH_SIZE = 128\n",
    "TOPK = 5\n",
    "COUNT = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7669232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'v2.2.14-lite'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from milvus import default_server\n",
    "from pymilvus import connections, utility\n",
    "\n",
    "default_server.start()\n",
    "connections.connect(host = \"127.0.0.1\", port = default_server.listen_port)\n",
    "\n",
    "utility.get_server_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01fa7915",
   "metadata": {},
   "outputs": [],
   "source": [
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2aff749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'title', 'abstract', 'label'], dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c38f4e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# object should be inserted in the format of (title, date, location, speech embedding)\n",
    "fields = [\n",
    "    FieldSchema(name = \"id\", dtype = DataType.INT64, is_primary = True, auto_id = True),\n",
    "    FieldSchema(name = \"title\", dtype = DataType.VARCHAR, max_length = 800),\n",
    "    FieldSchema(name = \"abstract\", dtype = DataType.VARCHAR, max_length = 9000),\n",
    "    FieldSchema(name = \"label\", dtype = DataType.VARCHAR, max_length = 20),\n",
    "    FieldSchema(name = \"embedding\", dtype = DataType.FLOAT_VECTOR, dim = DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields = fields)\n",
    "collection = Collection(name = COLLECTION_NAME, schema = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7fbcb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = {\n",
    "    \"index_type\": \"IVF_FLAT\",\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"nlist\": 100},\n",
    "}\n",
    "collection.create_index(field_name = \"embedding\", index_params = index_params)\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830b9181",
   "metadata": {},
   "source": [
    "Create Vector Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734f20d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create cohere embeddings\n",
    "# # Set up a co:here client.\n",
    "cohere_client = cohere.Client(\"enter-your-api-key\")#prod key\n"
    
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c54e61bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from questions using Cohere\n",
    "def embed(texts):\n",
    "    res = cohere_client.embed(texts, model = \"embed-english-v3.0\", input_type = \"search_document\")\n",
    "    return res.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d08ef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 79/79 [07:51<00:00,  5.97s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#total = pd.DataFrame()\n",
    "for batch in tqdm(np.array_split(arxiv, (COUNT/BATCH_SIZE) + 1)):\n",
    "    #titles = \n",
    "    abstracts = batch['abstract'].tolist()\n",
    "    data = [\n",
    "        batch['title'].tolist(),\n",
    "        abstracts,\n",
    "        batch['label'].tolist(),\n",
    "        embed(abstracts)\n",
    "    ]\n",
    "\n",
    "    collection.insert(data)\n",
    "\n",
    "# Flush at end to make sure all rows are sent for indexing\n",
    "collection.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "257fd2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What papers talk about astrophysics?\n",
      "Search Time: 0.08154153823852539\n",
      "Results:\n",
      "\n",
      "Cosmic Magnetism ---- 0.888\n",
      "\n",
      "  Magnetic fields are involved in every astrophysical process on every scale:\n",
      "from planetary and stellar interiors to neutron stars, stellar wind bubbles and\n",
      "supernova remnants; from the interstellar medium in galactic disks, nuclei,\n",
      "spiral arms and halos to the intracluster and intergalactic media. They are\n",
      "involved in essentially every particle acceleration process and are thus\n",
      "fundamental to non-thermal physics in the Universe. Key questions include the\n",
      "origin of magnetic fields, their evolution over cosmic time, the amplification\n",
      "and decay processes that modify their strength, and their impact on other\n",
      "processes such as star formation and galaxy evolution. Astrophysical plasmas\n",
      "provide a unique laboratory for testing magnetic dynamo theory. The study of\n",
      "magnetic fields requires observations that span the wavelength range from radio\n",
      "through infrared, optical, UV, X-ray, and gamma-ray.\n",
      "  Canada has an extremely strong record of research in cosmic magnetism, and\n",
      "has a significant leadership role in several ongoing and upcoming global\n",
      "programs. This white paper will review the science questions to be addressed in\n",
      "the study of cosmic magnetic fields and will describe the observational and\n",
      "theoretical opportunities and challenges afforded by the telescopes and\n",
      "modelling capabilities of today and tomorrow.\n",
      " ---- 0.888\n",
      "\n",
      "Increasing the Discovery Space in Astrophysics - A Collation of Six\n",
      "  Submitted White Papers ---- 0.889\n",
      "\n",
      "  We write in response to the call from the 2020 Decadal Survey to submit white\n",
      "papers illustrating the most pressing scientific questions in astrophysics for\n",
      "the coming decade. We propose exploration as the central question for the\n",
      "Decadal Committee's discussions.The history of astronomy shows that paradigm\n",
      "changing discoveries are not driven by well formulated scientific questions,\n",
      "based on the knowledge of the time. They were instead the result of the\n",
      "increase in discovery space fostered by new telescopes and instruments. An\n",
      "additional tool for increasing the discovery space is provided by the analysis\n",
      "and mining of the increasingly larger amount of archival data available to\n",
      "astronomers. Revolutionary observing facilities, and the state of the art\n",
      "astronomy archives needed to support these facilities, will open up the\n",
      "universe to new discovery. Here we focus on exploration for compact objects and\n",
      "multi messenger science. This white paper includes science examples of the\n",
      "power of the discovery approach, encompassing all the areas of astrophysics\n",
      "covered by the 2020 Decadal Survey.\n",
      " ---- 0.889\n",
      "\n",
      "The role of Active Galactic Nuclei in galaxy evolution: insights from\n",
      "  space ultraviolet spectropolarimetry ---- 0.891\n",
      "\n",
      "  This Astro2020 white paper summarizes the unknowns of active galactic nuclei\n",
      "(AGN) physics that could be unveiled thanks to a new, space-born, ultraviolet\n",
      "spectropolarimeter. The unique capabilities of high energy polarimetry would\n",
      "help us to understand the precise mechanisms of matter and energy transfer and\n",
      "supermassive black holes growth, together with the impact of AGN feedback on\n",
      "galaxy evolution.\n",
      " ---- 0.891\n",
      "\n",
      "What is the nature and origin of the highest-energy particles in the\n",
      "  universe? ---- 0.891\n",
      "\n",
      "  This white paper was submitted to the US Astronomy and Astrophysics Decadal\n",
      "Survey (Astro2020) and defines the science questions to be answered in the next\n",
      "decade in the field of Ultra-High Energy Cosmic-Rays. Following a review of the\n",
      "recent experimental and theoretical advances in the field, the paper outlines\n",
      "strategies and requirements desirable for the design of future experiments.\n",
      " ---- 0.891\n",
      "\n",
      "Cosmology and the Early Universe ---- 0.894\n",
      "\n",
      "  This Astro-2020 White Paper deals with what we might learn from future\n",
      "gravitational wave observations about the early universe phase transitions and\n",
      "their energy scales, primordial black holes, Hubble parameter, dark matter and\n",
      "dark energy, modified theories of gravity and extra dimensions.\n",
      " ---- 0.894\n",
      "\n",
      "\n",
      "Query: What are the papers on that discuss computer architecture?\n",
      "Search Time: 0.08154153823852539\n",
      "Results:\n",
      "\n",
      "Intelligent Architectures for Intelligent Machines ---- 0.927\n",
      "\n",
      "  Computing is bottlenecked by data. Large amounts of application data\n",
      "overwhelm storage capability, communication capability, and computation\n",
      "capability of the modern machines we design today. As a result, many key\n",
      "applications' performance, efficiency and scalability are bottlenecked by data\n",
      "movement. In this keynote talk, we describe three major shortcomings of modern\n",
      "architectures in terms of 1) dealing with data, 2) taking advantage of the vast\n",
      "amounts of data, and 3) exploiting different semantic properties of application\n",
      "data. We argue that an intelligent architecture should be designed to handle\n",
      "data well. We show that handling data well requires designing architectures\n",
      "based on three key principles: 1) data-centric, 2) data-driven, 3) data-aware.\n",
      "We give several examples for how to exploit each of these principles to design\n",
      "a much more efficient and high performance computing system. We especially\n",
      "discuss recent research that aims to fundamentally reduce memory latency and\n",
      "energy, and practically enable computation close to data, with at least two\n",
      "promising novel directions: 1) performing massively-parallel bulk operations in\n",
      "memory by exploiting the analog operational properties of memory, with low-cost\n",
      "changes, 2) exploiting the logic layer in 3D-stacked memory technology in\n",
      "various ways to accelerate important data-intensive applications. We discuss\n",
      "how to enable adoption of such fundamentally more intelligent architectures,\n",
      "which we believe are key to efficiency, performance, and sustainability. We\n",
      "conclude with some guiding principles for future computing architecture and\n",
      "system designs.\n",
      " ---- 0.927\n",
      "\n",
      "BRISC-V: An Open-Source Architecture Design Space Exploration Toolbox ---- 0.997\n",
      "\n",
      "  In this work, we introduce a platform for register-transfer level (RTL)\n",
      "architecture design space exploration. The platform is an open-source,\n",
      "parameterized, synthesizable set of RTL modules for designing RISC-V based\n",
      "single and multi-core architecture systems. The platform is designed with a\n",
      "high degree of modularity. It provides highly-parameterized, composable RTL\n",
      "modules for fast and accurate exploration of different RISC-V based core\n",
      "complexities, multi-level caching and memory organizations, system topologies,\n",
      "router architectures, and routing schemes. The platform can be used for both\n",
      "RTL simulation and FPGA based emulation. The hardware modules are implemented\n",
      "in synthesizable Verilog using no vendor-specific blocks. The platform includes\n",
      "a RISC-V compiler toolchain to assist in developing software for the cores, a\n",
      "web-based system configuration graphical user interface (GUI) and a web-based\n",
      "RISC-V assembly simulator. The platform supports a myriad of RISC-V\n",
      "architectures, ranging from a simple single cycle processor to a multi-core SoC\n",
      "with a complex memory hierarchy and a network-on-chip. The modules are designed\n",
      "to support incremental additions and modifications. The interfaces between\n",
      "components are particularly designed to allow parts of the processor such as\n",
      "whole cache modules, cores or individual pipeline stages, to be modified or\n",
      "replaced without impacting the rest of the system. The platform allows\n",
      "researchers to quickly instantiate complete working RISC-V multi-core systems\n",
      "with synthesizable RTL and make targeted modifications to fit their needs. The\n",
      "complete platform (including Verilog source code) can be downloaded at\n",
      "https://ascslab.org/research/briscv/explorer/explorer.html.\n",
      " ---- 0.997\n",
      "\n",
      "DRMap: A Generic DRAM Data Mapping Policy for Energy-Efficient\n",
      "  Processing of Convolutional Neural Networks ---- 1.013\n",
      "\n",
      "  Many convolutional neural network (CNN) accelerators face performance- and\n",
      "energy-efficiency challenges which are crucial for embedded implementations,\n",
      "due to high DRAM access latency and energy. Recently, some DRAM architectures\n",
      "have been proposed to exploit subarray-level parallelism for decreasing the\n",
      "access latency. Towards this, we present a design space exploration methodology\n",
      "to study the latency and energy of different mapping policies on different DRAM\n",
      "architectures, and identify the pareto-optimal design choices. The results show\n",
      "that the energy-efficient DRAM accesses can be achieved by a mapping policy\n",
      "that orderly prioritizes to maximize the row buffer hits, bank- and\n",
      "subarray-level parallelism.\n",
      " ---- 1.013\n",
      "\n",
      "A Workload and Programming Ease Driven Perspective of\n",
      "  Processing-in-Memory ---- 1.019\n",
      "\n",
      "  Many modern and emerging applications must process increasingly large volumes\n",
      "of data. Unfortunately, prevalent computing paradigms are not designed to\n",
      "efficiently handle such large-scale data: the energy and performance costs to\n",
      "move this data between the memory subsystem and the CPU now dominate the total\n",
      "costs of computation. This forces system architects and designers to\n",
      "fundamentally rethink how to design computers. Processing-in-memory (PIM) is a\n",
      "computing paradigm that avoids most data movement costs by bringing computation\n",
      "to the data. New opportunities in modern memory systems are enabling\n",
      "architectures that can perform varying degrees of processing inside the memory\n",
      "subsystem. However, there are many practical system-level issues that must be\n",
      "tackled to construct PIM architectures, including enabling workloads and\n",
      "programmers to easily take advantage of PIM. This article examines three key\n",
      "domains of work towards the practical construction and widespread adoption of\n",
      "PIM architectures. First, we describe our work on systematically identifying\n",
      "opportunities for PIM in real applications, and quantify potential gains for\n",
      "popular emerging applications (e.g., machine learning, data analytics, genome\n",
      "analysis). Second, we aim to solve several key issues on programming these\n",
      "applications for PIM architectures. Third, we describe challenges that remain\n",
      "for the widespread adoption of PIM.\n",
      " ---- 1.019\n",
      "\n",
      "A Modern Primer on Processing in Memory ---- 1.029\n",
      "\n",
      "  Modern computing systems are overwhelmingly designed to move data to\n",
      "computation. This design choice goes directly against at least three key trends\n",
      "in computing that cause performance, scalability and energy bottlenecks: (1)\n",
      "data access is a key bottleneck as many important applications are increasingly\n",
      "data-intensive, and memory bandwidth and energy do not scale well, (2) energy\n",
      "consumption is a key limiter in almost all computing platforms, especially\n",
      "server and mobile systems, (3) data movement, especially off-chip to on-chip,\n",
      "is very expensive in terms of bandwidth, energy and latency, much more so than\n",
      "computation. These trends are especially severely-felt in the data-intensive\n",
      "server and energy-constrained mobile systems of today. At the same time,\n",
      "conventional memory technology is facing many technology scaling challenges in\n",
      "terms of reliability, energy, and performance. As a result, memory system\n",
      "architects are open to organizing memory in different ways and making it more\n",
      "intelligent, at the expense of higher cost. The emergence of 3D-stacked memory\n",
      "plus logic, the adoption of error correcting codes inside the latest DRAM\n",
      "chips, proliferation of different main memory standards and chips, specialized\n",
      "for different purposes (e.g., graphics, low-power, high bandwidth, low\n",
      "latency), and the necessity of designing new solutions to serious reliability\n",
      "and security issues, such as the RowHammer phenomenon, are an evidence of this\n",
      "trend. This chapter discusses recent research that aims to practically enable\n",
      "computation close to data, an approach we call processing-in-memory (PIM). PIM\n",
      "places computation mechanisms in or near where the data is stored (i.e., inside\n",
      "the memory chips, in the logic layer of 3D-stacked memory, or in the memory\n",
      "controllers), so that data movement between the computation units and memory is\n",
      "reduced or eliminated.\n",
      " ---- 1.029\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "search_terms = [\"What papers talk about astrophysics?\", \"What are the papers on that discuss computer architecture?\"]\n",
    "\n",
    "# Search the database based on input text\n",
    "def embed_search(data):\n",
    "    embeds = cohere_client.embed(data, model = \"embed-english-v3.0\", input_type = \"search_query\") \n",
    "    return [x for x in embeds]\n",
    "\n",
    "search_data = embed_search(search_terms)\n",
    "\n",
    "start = time.time()\n",
    "res = collection.search(\n",
    "    data = search_data,  # Embed search value\n",
    "    anns_field = \"embedding\",  # Search across embeddings\n",
    "    param = {\"metric_type\": \"L2\",\n",
    "            \"params\": {\"nprobe\": 20}},\n",
    "    limit = TOPK,  # Limit to top_k results per search\n",
    "    output_fields = [\"title\",\"abstract\"]  # Include title field in result \n",
    ")\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "for hits_i, hits in enumerate(res):\n",
    "    print(\"Query:\", search_terms[hits_i])\n",
    "    #print(\"Abstract:\", search_terms[hits_i])\n",
    "    print(\"Search Time:\", end-start)\n",
    "    print(\"Results:\\n\")\n",
    "    for hit in hits:\n",
    "        print( hit.entity.get(\"title\"), \"----\", round(hit.distance, 3))\n",
    "        print()\n",
    "        print( hit.entity.get(\"abstract\"), \"----\", round(hit.distance, 3))\n",
    "        print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5303d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
